{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Contrastive-Predictive-Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"./img/overview.png\"></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Encoder: Strided convolutional layers with resnet blocks\n",
    "#### Autoregressive model: GRUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"./img/log-bilinear-model.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(self, x, hidden):\n",
    "    batch = x.size()[0]  # batch = 64\n",
    "    nce = 0  # average over timestep and batch and gpus\n",
    "\n",
    "    # Strided convolutional layers with resnet blocks\n",
    "    # input sequence(x) is N*C*L, e.g. 64*1*20480\n",
    "    z = self.encoder(x)\n",
    "    # encoded sequence(z) is N*C*L, e.g. 64*512*128\n",
    "\n",
    "    # reshape to N*L*C for GRU, e.g. 64*128*512\n",
    "    z = z.transpose(1, 2)\n",
    "\n",
    "    # 샘플링\n",
    "    # self.seq_len = 20480 -> \"window length to sample from each utterance\", utterance: 발화\n",
    "    # 20480 / 160 = 128\n",
    "    # self.timestep = 12\n",
    "    t_samples = torch.randint(int(self.seq_len / 160) - self.timestep, size=(1,)).long()  # high=116, low=0(default)\n",
    "    encode_samples = torch.empty((self.timestep, batch, 512)).float()  # e.g. size 12*64*512\n",
    "    for i in np.arange(1, self.timestep + 1):  # 12회 반복\n",
    "        encode_samples[i - 1] = z[:, t_samples + i, :].view(batch, 512)  # z_tk e.g. size 64*512,  12*64*512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "<img src=\"./img/context-latent-representation.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    # GRU\n",
    "    forward_seq = z[:, : t_samples + 1, :]  # e.g. size 64*100*512\n",
    "    output1, hidden1 = self.gru1(forward_seq, hidden1)  # output size e.g. 64*100*256\n",
    "    c_t = output1[:, t_samples, :].view(batch, 128)  # c_t e.g. size 64*128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"./img/overview.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"./img/log-bilinear-model.png\"></img>   (3)\n",
    "<img src=\"./img/prediction.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    # Predictions\n",
    "    pred = torch.empty((self.timestep, batch, 512)).float()  # e.g. size 12*64*512\n",
    "    \n",
    "    # self.Wk1 = nn.ModuleList([nn.Linear(128, 512) for i in range(timestep)])   # 12개의 linear 함수\n",
    "    for i in np.arange(0, self.timestep):  # 12회 반복\n",
    "        linear = self.Wk1[i]  # c_t 벡터 1개를 반복해서 서로 다른 linear 함수의 input으로 사용함\n",
    "        pred[i] = linear(c_t)  # Wk*c_t e.g. size 64*512,  결과적으로 pred는 12*64*512, 12steps 만큼 예측함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### torch.eq(): Computes element-wise equality\n",
    "<img src=\"./img/torch-eq.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### torch.argmax(input): Returns the indices of the maximum value of all elements in the input tensor.\n",
    "### torch.argmax(input, dim, keepdim=False): Returns the indices of the maximum values of a tensor across a dimension.\n",
    "<img src=\"./img/torch-argmax-dim.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "    for i in np.arange(0, self.timestep):  # 12회 반복\n",
    "        total = torch.mm(encode_samples[i], torch.transpose(pred[i], 0, 1))  # e.g. size 64*64\n",
    "\n",
    "        # labels of negative sample\n",
    "        correct = torch.sum(\n",
    "            torch.eq(\n",
    "                torch.argmax(self.softmax(total), dim=0),\n",
    "                torch.arange(0, batch)\n",
    "            )\n",
    "        )  # correct is a tensor\n",
    "\n",
    "        nce += torch.sum(\n",
    "            torch.diag(\n",
    "                self.log_softmax(total)\n",
    "            )\n",
    "        )  # nce is a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## e.g. correct1 (1)\n",
    "<img src=\"./img/correct1.png\"></img>\n",
    "## e.g. correct1 (2)\n",
    "<img src=\"./img/correct2.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"./img/nce-loss-1.png\"></img>\n",
    "<img src=\"./img/nce-loss-2.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src=\"./img/diag.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## take the diagonal, which corresponds to positive samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## e.g. log softmax, diag, nce loss (1)\n",
    "<img src=\"./img/diag1.png\"></img>\n",
    "==========================================================================================================\n",
    "## e.g. log softmax, diag, nce loss (2)\n",
    "<img src=\"./img/diag2.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "        nce += torch.sum(\n",
    "            torch.diag(\n",
    "                self.log_softmax(total)\n",
    "            )\n",
    "        )  # nce is a tensor\n",
    "\n",
    "    nce /= -1.0 * batch * self.timestep\n",
    "    accuracy = 1.0 * correct.item() / batch\n",
    "\n",
    "    return accuracy, nce, hidden"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37c5bdf41c9952d71251ac72cfceed86a0aec15ccb5fa830065b304123a0d72a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('constrative_predictive_coding')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
